{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9a37e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 and 1 is 0\n",
      "1 and 0 is 1\n",
      "0 and 1 is 0\n",
      "0 and 0 is 0\n"
     ]
    }
   ],
   "source": [
    "## assi 2\n",
    "\n",
    "def mc_cu(x1,x2):\n",
    "    w1 = -1\n",
    "    w2 = 1\n",
    "\n",
    "    theta = 0\n",
    "\n",
    "    w_sum = x1*w1 + x2*w2\n",
    "\n",
    "    op = 0 if w_sum >= theta else 1\n",
    "    return op\n",
    "\n",
    "inputs = [(1,1),(1,0),(0,1),(0,0)]\n",
    "\n",
    "for x1,x2 in inputs:\n",
    "    res = mc_cu(x1,x2)\n",
    "    print(f'{x1} and {x2} is {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbbfd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the no 010 is even\n",
      "the no 111 is odd\n",
      "the no 110 is even\n",
      "the no 110 is even\n"
     ]
    }
   ],
   "source": [
    "## assi 3 \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self,input_size):\n",
    "        self.weight = np.zeros(input_size + 1)\n",
    "    \n",
    "    def predict(self,inputs):\n",
    "        sum = np.dot(inputs, self.weight[1:]) + self.weight[0]\n",
    "        return 1 if sum >=0 else 0\n",
    "    \n",
    "    def train(self,inputss,labels,epochs):\n",
    "        for _ in range(epochs):\n",
    "            for inputs,label in zip(inputss,labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weight[1:] += (label-prediction) * np.array(inputs)\n",
    "                self.weight[0] += (label-prediction) \n",
    "inputss = ([\n",
    "    [0,0,0],\n",
    "    [0,0,1],\n",
    "    [0,1,0],\n",
    "    [0,1,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1],\n",
    "    [1,1,0],\n",
    "    [1,1,1]\n",
    "])\n",
    "labels = [0,1,0,1,0,1,0,1,0,1] # 0 = even and 1 = odd\n",
    "perceptron = Perceptron(len(inputss[0]))\n",
    "perceptron.train(inputss,labels,epochs = 100)\n",
    "\n",
    "test = ([\n",
    "    [0,1,0],\n",
    "    [1,1,1],\n",
    "    [1,1,0],\n",
    "    [1,1,0]\n",
    "])\n",
    "for inputs in test:\n",
    "    res = perceptron.predict(inputs)\n",
    "    no = ''.join(str(bit) for bit in inputs)\n",
    "    print(f\"the no {no} is {'odd' if res == 1 else 'even'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0695e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## assin 4\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define the dataset\n",
    "data = np.array([\n",
    "    [1, 2, -1],\n",
    "    [2, 3, -1],\n",
    "    [3, 3, 1],\n",
    "    [2, 1, 1],\n",
    "    [1, 4, -1],\n",
    "    [2, 3, -2],\n",
    "    [1, 3, -1],\n",
    "])\n",
    "\n",
    "# separate data and labels\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# initialize weights\n",
    "w = np.zeros(len(X[0]))\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "# Perceptron learning algorithm\n",
    "for epoch in range(epochs):\n",
    "    #2d arry\n",
    "    for i, x in enumerate(X):\n",
    "        if (np.dot(X[i], w) * y[i]) <= 0:\n",
    "            w = w + learning_rate * X[i] * y[i]\n",
    "\n",
    "# plot the data\n",
    "for i, x in enumerate(X):\n",
    "    if y[i] > 0:\n",
    "        plt.scatter(x[0], x[1], color='b')\n",
    "    else:\n",
    "        plt.scatter(x[0], x[1], color='r')\n",
    "\n",
    "# plot the decision boundary\n",
    "x = np.linspace(0, 5)\n",
    "y = (-w[0] * x) / w[1]\n",
    "plt.plot(x, y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a12de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "## assin 7\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Initialize weights with random values\n",
    "        self.weights1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.weights2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        \n",
    "        # Initialize biases with zeros\n",
    "        self.bias1 = np.zeros((1, self.hidden_size))\n",
    "        self.bias2 = np.zeros((1, self.output_size))\n",
    "        \n",
    "    def forward_propagation(self, X):\n",
    "        self.hidden_layer = np.dot(X, self.weights1) + self.bias1\n",
    "        self.hidden_activation = self.sigmoid(self.hidden_layer)\n",
    "        self.output_layer = np.dot(self.hidden_activation, self.weights2) + self.bias2\n",
    "        self.output_activation = self.sigmoid(self.output_layer)\n",
    "        return self.output_activation\n",
    "    \n",
    "    def backward_propagation(self, X, y, output_activation, learning_rate):\n",
    "        error = y - output_activation\n",
    "        delta_output = error * self.sigmoid_derivative(output_activation)\n",
    "        \n",
    "        error_hidden = delta_output.dot(self.weights2.T)\n",
    "        delta_hidden = error_hidden * self.sigmoid_derivative(self.hidden_activation)\n",
    "        \n",
    "        self.weights2 += self.hidden_activation.T.dot(delta_output) * learning_rate\n",
    "        self.bias2 += np.sum(delta_output, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "        self.weights1 += X.T.dot(delta_hidden) * learning_rate\n",
    "        self.bias1 += np.sum(delta_hidden, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output_activation = self.forward_propagation(X)\n",
    "            self.backward_propagation(X, y, output_activation, learning_rate)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        output_activation = self.forward_propagation(X)\n",
    "        predictions = np.round(output_activation)\n",
    "        return predictions\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Create a neural network with 2 input neurons, 2 hidden neurons, and 1 output neuron\n",
    "nn = NeuralNetwork(input_size=2, hidden_size=2, output_size=1)\n",
    "\n",
    "# Train the neural network\n",
    "nn.train(X, y, epochs=10000, learning_rate=0.1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nn.predict(X)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "### ANN A7 and B1 practice\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.w1 = np.random.rand(input_size,hidden_size)\n",
    "        self.w2 = np.random.rand(hidden_size,output_size)\n",
    "        \n",
    "        self.b1 = np.zeros((1,hidden_size))\n",
    "        self.b2 = np.zeros((1,output_size))\n",
    "        \n",
    "    def Feedforward(self,X):\n",
    "        \n",
    "        self.hidden_layer = np.dot(X,self.w1) + self.b1\n",
    "        self.hidden_layer_acti = self.sigmoid(self.hidden_layer)\n",
    "        self.output_layer = np.dot(self.hidden_layer_acti,self.w2) + self.b2\n",
    "        self.output_layer_acti = self.sigmoid(self.output_layer)\n",
    "        return self.output_layer_acti\n",
    "    \n",
    "    def Backpropagation(self,X,y,output_activation,l_rate):\n",
    "        error = y - output_activation\n",
    "        delta_op = error * self.sigmoid_der(output_activation)\n",
    "        \n",
    "        error_hidden = delta_op.dot(self.w2.T)\n",
    "        delta_hidden = error_hidden * self.sigmoid_der(self.hidden_layer_acti)\n",
    "        \n",
    "        self.w2 += self.hidden_layer_acti.T.dot(delta_op) * l_rate\n",
    "        self.b2 += np.sum(delta_op,axis=0,keepdims=True) * l_rate\n",
    "        \n",
    "        self.w1 += X.T.dot(delta_hidden) * l_rate\n",
    "        self.b1 += np.sum(delta_hidden,axis = 0,keepdims=True) * l_rate\n",
    "        \n",
    "    def train(self,X,y,epochs,l_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output_activation = self.Feedforward(X)\n",
    "            self.Backpropagation(X, y, output_activation, l_rate)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        output_activation = self.Feedforward(X)\n",
    "        prediction = np.round(output_activation)\n",
    "        return prediction\n",
    "    \n",
    "    def sigmoid(self,X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def sigmoid_der(self,X):\n",
    "        return X * (1- X)\n",
    "    \n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "nn = NeuralNetwork(input_size=2, hidden_size=2, output_size=1)\n",
    "\n",
    "nn.train(x, y, epochs = 10000, l_rate = 0.1)\n",
    "\n",
    "prediction = nn.predict(x)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd3381c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2360 - accuracy: 0.9305 - val_loss: 0.1345 - val_accuracy: 0.9602\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1003 - accuracy: 0.9696 - val_loss: 0.0890 - val_accuracy: 0.9712\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0690 - accuracy: 0.9786 - val_loss: 0.0887 - val_accuracy: 0.9727\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.0782 - val_accuracy: 0.9776\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.0858 - val_accuracy: 0.9763\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0302 - accuracy: 0.9899 - val_loss: 0.0818 - val_accuracy: 0.9771\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0908 - val_accuracy: 0.9769\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.0938 - val_accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.0972 - val_accuracy: 0.9761\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.1011 - val_accuracy: 0.9770\n",
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.977"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### assin c2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "    keras.layers.Conv2D(2, (3,3), input_shape=(28, 28)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics='accuracy')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b41c1137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 81ms/step - loss: 1.0467 - accuracy: 0.3333 - val_loss: 1.0140 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.9831 - accuracy: 0.4271 - val_loss: 0.9639 - val_accuracy: 0.4583\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9239 - accuracy: 0.6146 - val_loss: 0.9192 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8662 - accuracy: 0.6667 - val_loss: 0.8761 - val_accuracy: 0.5417\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8141 - accuracy: 0.6875 - val_loss: 0.8349 - val_accuracy: 0.5417\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7649 - accuracy: 0.7083 - val_loss: 0.7971 - val_accuracy: 0.5417\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7203 - accuracy: 0.7396 - val_loss: 0.7631 - val_accuracy: 0.5833\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6809 - accuracy: 0.7500 - val_loss: 0.7322 - val_accuracy: 0.7083\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6439 - accuracy: 0.7604 - val_loss: 0.7041 - val_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6114 - accuracy: 0.7708 - val_loss: 0.6785 - val_accuracy: 0.7500\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5824 - accuracy: 0.7812 - val_loss: 0.6548 - val_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5560 - accuracy: 0.7917 - val_loss: 0.6329 - val_accuracy: 0.7917\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5333 - accuracy: 0.7917 - val_loss: 0.6125 - val_accuracy: 0.7917\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5110 - accuracy: 0.8021 - val_loss: 0.5923 - val_accuracy: 0.7917\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4905 - accuracy: 0.8021 - val_loss: 0.5717 - val_accuracy: 0.7917\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4715 - accuracy: 0.8333 - val_loss: 0.5517 - val_accuracy: 0.7917\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4541 - accuracy: 0.8333 - val_loss: 0.5324 - val_accuracy: 0.7917\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4373 - accuracy: 0.8229 - val_loss: 0.5137 - val_accuracy: 0.7917\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4199 - accuracy: 0.8229 - val_loss: 0.4970 - val_accuracy: 0.7917\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4066 - accuracy: 0.8229 - val_loss: 0.4803 - val_accuracy: 0.7917\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3913 - accuracy: 0.8229 - val_loss: 0.4659 - val_accuracy: 0.7917\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3778 - accuracy: 0.8229 - val_loss: 0.4521 - val_accuracy: 0.7917\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3647 - accuracy: 0.8229 - val_loss: 0.4394 - val_accuracy: 0.7917\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3529 - accuracy: 0.8229 - val_loss: 0.4280 - val_accuracy: 0.8333\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3411 - accuracy: 0.8333 - val_loss: 0.4158 - val_accuracy: 0.8333\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3305 - accuracy: 0.8438 - val_loss: 0.4064 - val_accuracy: 0.8333\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3198 - accuracy: 0.8438 - val_loss: 0.3987 - val_accuracy: 0.8333\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3095 - accuracy: 0.8438 - val_loss: 0.3896 - val_accuracy: 0.7917\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3009 - accuracy: 0.8438 - val_loss: 0.3808 - val_accuracy: 0.7917\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2923 - accuracy: 0.8750 - val_loss: 0.3733 - val_accuracy: 0.7917\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2834 - accuracy: 0.8750 - val_loss: 0.3657 - val_accuracy: 0.8333\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2752 - accuracy: 0.8750 - val_loss: 0.3598 - val_accuracy: 0.8333\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2670 - accuracy: 0.8854 - val_loss: 0.3543 - val_accuracy: 0.8333\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2592 - accuracy: 0.8958 - val_loss: 0.3506 - val_accuracy: 0.8333\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2510 - accuracy: 0.9062 - val_loss: 0.3450 - val_accuracy: 0.8333\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2441 - accuracy: 0.9167 - val_loss: 0.3385 - val_accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2363 - accuracy: 0.9375 - val_loss: 0.3322 - val_accuracy: 0.8333\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2292 - accuracy: 0.9375 - val_loss: 0.3256 - val_accuracy: 0.8333\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2220 - accuracy: 0.9479 - val_loss: 0.3204 - val_accuracy: 0.8333\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2146 - accuracy: 0.9479 - val_loss: 0.3153 - val_accuracy: 0.8333\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2076 - accuracy: 0.9583 - val_loss: 0.3100 - val_accuracy: 0.8333\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2010 - accuracy: 0.9583 - val_loss: 0.3036 - val_accuracy: 0.8333\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1944 - accuracy: 0.9688 - val_loss: 0.2985 - val_accuracy: 0.8333\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1885 - accuracy: 0.9688 - val_loss: 0.2943 - val_accuracy: 0.8750\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1814 - accuracy: 0.9688 - val_loss: 0.2937 - val_accuracy: 0.8750\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1761 - accuracy: 0.9688 - val_loss: 0.2925 - val_accuracy: 0.8750\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1694 - accuracy: 0.9688 - val_loss: 0.2870 - val_accuracy: 0.8750\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1638 - accuracy: 0.9792 - val_loss: 0.2811 - val_accuracy: 0.8750\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1583 - accuracy: 0.9792 - val_loss: 0.2784 - val_accuracy: 0.8750\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1534 - accuracy: 0.9792 - val_loss: 0.2733 - val_accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1408 - accuracy: 1.0000\n",
      "Test loss: 0.140848770737648\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "### assin A8\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43066453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "### Assin ART\n",
    "import numpy as np\n",
    "\n",
    "class ART1:\n",
    "    def __init__(self, input_size, rho):\n",
    "        self.rho = rho\n",
    "        self.input_size = input_size\n",
    "        self.w = np.ones((input_size, ))\n",
    "\n",
    "    def train(self, X):\n",
    "        for i in range(X.shape[0]):\n",
    "            self._train_single(X[i])\n",
    "\n",
    "    def _train_single(self, X):\n",
    "        while True:\n",
    "            y = self.predict(X)\n",
    "            if np.sum(X[self.w==y]) / np.sum(X) >= self.rho:\n",
    "                self.w = X\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = np.dot(X, self.w)\n",
    "        return np.where(y > 0.5, 1, 0)  # Use a threshold of 0.5\n",
    "\n",
    "# Training data\n",
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "# Initialize the network\n",
    "art1 = ART1(input_size=X.shape[1], rho=0.6)\n",
    "\n",
    "# Train the network\n",
    "art1.train(X)\n",
    "\n",
    "# Test the network\n",
    "print(art1.predict([0, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae5e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5fdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
